{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "\n",
    "class BackpackGPT2Config(GPT2Config):\n",
    "  \"\"\"\n",
    "    This is the configuration class to store the configuration of a [`GPT2Model`] or a [`TFGPT2Model`]. It is used to\n",
    "    instantiate a Backpack GPT-2 model according to the specified arguments, defining the model architecture.\n",
    "\n",
    "    Configuration objects inherit from [`GPT2Config`] and can be used to control the model outputs. Read the\n",
    "    documentation from [`GPT2Config`] for more information.\n",
    "\n",
    "    Args:\n",
    "        num_senses (`int`, *optional*, defaults to 16):\n",
    "            The number of sense vectors to define for each word.\n",
    "        sense_intermediate_scale (`int`, *optional*, defaults ot 4):\n",
    "            The hidden dimensionality of the sense vector network.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    ```python\n",
    "    >>> from transformers import BackpackGPT2Config, BackpackGPT2Model\n",
    "\n",
    "    >>> # Initializing a GPT2 configuration\n",
    "    >>> configuration = BackpackGPT2Config()\n",
    "\n",
    "    >>> # Initializing a model (with random weights) from the configuration\n",
    "    >>> model = BackpackGPT2Model(configuration)\n",
    "\n",
    "    >>> # Accessing the model configuration\n",
    "    >>> configuration = model.config\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               vocab_size=50264,\n",
    "               num_senses=16,\n",
    "               sense_intermediate_scale=4,\n",
    "               n_positions=512,\n",
    "               scale_attn_by_inverse_layer_idx=True,\n",
    "               **kwargs,\n",
    "  ):\n",
    "    self.num_senses = num_senses\n",
    "    self.sense_intermediate_scale = sense_intermediate_scale\n",
    "    super().__init__(vocab_size=vocab_size, n_positions=n_positions, scale_attn_by_inverse_layer_idx=scale_attn_by_inverse_layer_idx, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.pytorch_utils import Conv1D\n",
    "from transformers.utils import (\n",
    "    ModelOutput,\n",
    "    logging,\n",
    ")\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model, GPT2PreTrainedModel\n",
    "#from content.configuration_backpack_gpt2 import BackpackGPT2Config\n",
    "\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackpackGPT2PreTrainedModel(GPT2PreTrainedModel):\n",
    "    \"\"\"\n",
    "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
    "    models.\n",
    "    \"\"\"\n",
    "    _keys_to_ignore_on_load_missing = [r\"attn.masked_bias\", r\"attn.bias\"]\n",
    "\n",
    "    config_class = BackpackGPT2Config\n",
    "    base_model_prefix = \"backpack\"\n",
    "    is_parallelizable = True\n",
    "    supports_gradient_checkpointing = False\n",
    "    _no_split_modules = [\"GPT2Block\", \"BackpackNoMixBlock\"]\n",
    "\n",
    "    def __init__(self, *inputs, **kwargs):\n",
    "        super().__init__(*inputs, **kwargs)\n",
    "\n",
    "class BackpackMLP(nn.Module):\n",
    "\n",
    "  def __init__(self, embed_dim, intermediate_dim, out_dim, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = Conv1D(intermediate_dim, embed_dim)\n",
    "        self.c_proj = Conv1D(out_dim, intermediate_dim)\n",
    "        self.act = ACT2FN[config.activation_function]\n",
    "        self.dropout = nn.Dropout(config.resid_pdrop)\n",
    "\n",
    "  def forward(self, hidden_states: Optional[Tuple[torch.FloatTensor]]) -> torch.FloatTensor:\n",
    "      hidden_states = self.c_fc(hidden_states)\n",
    "      hidden_states = self.act(hidden_states)\n",
    "      hidden_states = self.c_proj(hidden_states)\n",
    "      hidden_states = self.dropout(hidden_states)\n",
    "      return hidden_states\n",
    "\n",
    "class BackpackNoMixBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.ln_1 = nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon)\n",
    "    self.ln_2 = nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon)\n",
    "    self.mlp = BackpackMLP(config.n_embd, config.n_embd*4, config.n_embd, config)\n",
    "    self.resid_dropout1 = nn.Dropout(config.resid_pdrop)\n",
    "    self.resid_dropout2 = nn.Dropout(config.resid_pdrop)\n",
    "\n",
    "  def forward(self, hidden_states, residual):\n",
    "    residual = self.resid_dropout1(hidden_states) + residual\n",
    "    hidden_states = self.ln_1(residual)\n",
    "    mlp_out = self.mlp(hidden_states)\n",
    "    residual = self.resid_dropout2(mlp_out) + residual\n",
    "    hidden_states = self.ln_2(residual)\n",
    "    return hidden_states\n",
    "\n",
    "\n",
    "class BackpackSenseNetwork(nn.Module):\n",
    "    def __init__(self, config, num_senses, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.num_senses = num_senses\n",
    "        #self.embeddings = embeddings\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "        self.dropout = nn.Dropout(config.embd_pdrop)\n",
    "        self.block = BackpackNoMixBlock(config)\n",
    "        self.ln = nn.LayerNorm(self.n_embd, eps=config.layer_norm_epsilon)\n",
    "        self.final_mlp = BackpackMLP(\n",
    "            embed_dim=config.n_embd,\n",
    "            intermediate_dim=config.sense_intermediate_scale*config.n_embd,\n",
    "            out_dim=config.n_embd*config.num_senses,\n",
    "            config=config,\n",
    "            )\n",
    "\n",
    "    def forward(self, input_embeds):\n",
    "      residual = self.dropout(input_embeds)\n",
    "      hidden_states = self.ln(residual)\n",
    "      hidden_states = self.block(hidden_states, residual)\n",
    "      senses = self.final_mlp(hidden_states)\n",
    "      bs, s, nvd = senses.shape\n",
    "      return senses.reshape(bs, s, self.num_senses, self.n_embd).transpose(1,2) # (bs, nv, s, d)\n",
    "\n",
    "class BackpackWeightNetwork(nn.Module):\n",
    "\n",
    "  def __init__(self, num_senses, embed_dim):\n",
    "    super().__init__()\n",
    "    self.n_embd = embed_dim\n",
    "    self.num_senses = num_senses\n",
    "    self.embed_per_sense = embed_dim // num_senses\n",
    "    self.c_attn = nn.Linear(embed_dim, 2 * num_senses * self.embed_per_sense)\n",
    "    self.softmax_scale = None\n",
    "\n",
    "  def forward(self, encoded):\n",
    "    b, s, d = encoded.shape\n",
    "    encoded = self.c_attn(encoded) # (b, s, 2*d)\n",
    "    encoded = encoded.reshape(b, s, 2, self.num_senses, self.embed_per_sense) #(b, s, 2, nv, d//nv)\n",
    "    batch_size, seqlen = encoded.shape[0], encoded.shape[1]\n",
    "\n",
    "    # compute scores & mask\n",
    "    q, k = encoded.unbind(dim=2)\n",
    "    softmax_scale = self.softmax_scale or 1.0 / math.sqrt(q.shape[-1])\n",
    "    scores = torch.einsum('bthd,bshd->bhts', q, k * softmax_scale)\n",
    "    causal_mask = torch.triu(torch.full((seqlen, seqlen), -10000.0, device=scores.device), 1)\n",
    "    scores = scores + causal_mask.to(dtype=scores.dtype)\n",
    "\n",
    "    return torch.softmax(scores, dim=-1, dtype=q.dtype)\n",
    "  \n",
    "\n",
    "@dataclass\n",
    "class BackpackGPT2BaseModelOutput(ModelOutput):\n",
    "    hidden_states: torch.FloatTensor = None\n",
    "    contextualization: torch.FloatTensor = None\n",
    "\n",
    "class BackpackGPT2Model(BackpackGPT2PreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\".*attn.masked_bias\", r\".*attn.bias\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.embed_dim = config.n_embd\n",
    "\n",
    "        self.num_senses = config.num_senses\n",
    "        self.gpt2_model = GPT2Model(config)\n",
    "        self.sense_network = BackpackSenseNetwork(config, self.num_senses, self.gpt2_model.wte)\n",
    "        self.word_embeddings = self.gpt2_model.wte\n",
    "        self.position_embeddings = self.gpt2_model.wpe\n",
    "        self.sense_weight_net = BackpackWeightNetwork(self.num_senses, self.embed_dim)\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def get_num_senses(self):\n",
    "        return self.num_senses\n",
    "\n",
    "    def get_word_embeddings(self):\n",
    "        return self.word_embeddings\n",
    "\n",
    "    def get_sense_network(self):\n",
    "        return self.sense_network\n",
    "\n",
    "    def forward(self, input_ids, position_ids):\n",
    "        # Compute senses\n",
    "        sense_input_embeds = self.word_embeddings(input_ids)\n",
    "        senses = self.sense_network(sense_input_embeds) # (bs, nv, s, d)\n",
    "\n",
    "        # Compute contextualization weights\n",
    "        contextl_hidden_states = self.gpt2_model(input_ids, position_ids=position_ids).last_hidden_state # (bs, s, d)\n",
    "        contextualization = self.sense_weight_net(contextl_hidden_states) # (bs, nv, s, s)\n",
    "\n",
    "        # Compute resulting outputs\n",
    "        hidden_states = torch.sum(contextualization @ senses, dim=1) # (bs, nv, s, d) -> (bs, s, d)\n",
    "        return BackpackGPT2BaseModelOutput(\n",
    "            hidden_states=hidden_states,\n",
    "            contextualization=contextualization,\n",
    "        )\n",
    "    \n",
    "    def run_with_custom_contextualization(self, input_ids, contextualization):\n",
    "        # Compute senses\n",
    "        sense_input_embeds = self.word_embeddings(input_ids)\n",
    "        senses = self.sense_network(sense_input_embeds) # (bs, nv, s, d)\n",
    "\n",
    "        # Compute resulting outputs\n",
    "        hidden_states = torch.sum(contextualization @ senses, dim=1) # (bs, nv, s, d) -> (bs, s, d)\n",
    "        return BackpackGPT2BaseModelOutput(\n",
    "            hidden_states=hidden_states,\n",
    "            contextualization=contextualization,\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class BackpackGPT2LMHeadModelOutput(ModelOutput):\n",
    "    logits: torch.FloatTensor = None\n",
    "    contextualization: torch.FloatTensor = None\n",
    "\n",
    "class BackpackGPT2LMHeadModel(BackpackGPT2PreTrainedModel):\n",
    "  _keys_to_ignore_on_load_missing = [r\".*attn.masked_bias\", r\".*attn.bias\"]\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "    self.backpack = BackpackGPT2Model(config)\n",
    "    self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "    # Model parallel\n",
    "    self.model_parallel = False\n",
    "    self.device_map = None\n",
    "\n",
    "    self.tie_weights()\n",
    "\n",
    "  def tie_weights(self):\n",
    "      self.lm_head.weight = self.backpack.word_embeddings.weight # also tied with the underlying underlying transf\n",
    "\n",
    "  def get_lm_head(self):\n",
    "      return self.lm_head\n",
    "\n",
    "  def forward(self, input_ids, position_ids=None):\n",
    "      outputs = self.backpack(input_ids, position_ids=position_ids)\n",
    "      hidden_states, contextualization = outputs.hidden_states, outputs.contextualization\n",
    "      lm_logits = self.lm_head(hidden_states) # (bs, s, V)\n",
    "      return BackpackGPT2LMHeadModelOutput(\n",
    "            logits=lm_logits,\n",
    "            contextualization=contextualization,\n",
    "        )\n",
    "\n",
    "  def run_with_custom_contextualization(self, input_ids, contextualization):\n",
    "      outputs = self.backpack.run_with_custom_contextualization(input_ids, contextualization)\n",
    "      hidden_states, contextualization = outputs.hidden_states, outputs.contextualization\n",
    "      lm_logits = self.lm_head(hidden_states)\n",
    "      return BackpackGPT2LMHeadModelOutput(\n",
    "        logits=lm_logits,\n",
    "        contextualization=contextualization,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON config file\n",
    "config_file_path = 'config.json'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(config_file_path, 'r') as config_file:\n",
    "    # Load the JSON data\n",
    "    config_data = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BackpackGPT2Config(**config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BackpackGPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/home/piyush/srinath/NLP/Project/NLP/Hamvir/pytorch_model.bin\", map_location=torch.device('cuda'))  # You can specify the device (e.g., 'cuda:0') if using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "for key, value in checkpoint.items():\n",
    "    new_state_dict[key] = value\n",
    "\n",
    "# Load the new_state_dict into the model\n",
    "model.load_state_dict(new_state_dict, strict=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"stanfordnlp/backpack-gpt2\"\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "torch_model = AutoModelForCausalLM.from_pretrained(model_id, config=config, trust_remote_code=True)\n",
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.randint(0, 50264, (1, 512), dtype=torch.long)\n",
    "# torch_out = torch_model(\n",
    "#     input,\n",
    "#     position_ids=None,\n",
    "# )\n",
    "# torch_out = torch.nn.functional.softmax(torch_out.logits, dim=-1)\n",
    "# print(torch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"stanfordnlp/backpack-gpt2\"\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, config=config, trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\",pad_token = '<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        sentences = [line.strip() for line in file if line.strip()]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     input_list\u001b[38;5;241m.\u001b[39mappend(input_tokens)\n\u001b[1;32m     18\u001b[0m     output_list\u001b[38;5;241m.\u001b[39mappend(output_tokens)\n\u001b[0;32m---> 19\u001b[0m input_ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m output_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(output_list)\n\u001b[1;32m     21\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m model(input_)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "total_tokens = 0\n",
    "folder_path = '/home/piyush/srinath/NLP/Project/NLP/dataset/openwebtext'\n",
    "for files in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path,files)\n",
    "    sentences = read_sentences(file_path)\n",
    "    input_list = []\n",
    "    output_list = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        input_ = tokenizer.bos_token + sentence\n",
    "        output_ = sentence + tokenizer.eos_token\n",
    "        input_tokens = tokenizer(input_, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        output_tokens = tokenizer(output_, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        input_tokens = input_tokens['input_ids']\n",
    "        output_tokens = output_tokens['input_ids']\n",
    "        input_list.append(input_tokens)\n",
    "        output_list.append(output_tokens)\n",
    "    print(len(input_list))\n",
    "    input_ = torch.tensor(input_list)\n",
    "    output_ = torch.tensor(output_list)\n",
    "    model_outputs = model(input_)\n",
    "    output_logits = model_outputs['logits']\n",
    "    # print(output_logits.shape,output_tokens.shape)\n",
    "    loss = _loss(output_logits.view(-1, output_logits.size(-1)), output_.view(-1))\n",
    "        \n",
    "\n",
    "    #     # Accumulate total loss and total tokens\n",
    "    #     total_loss += loss.item()\n",
    "    #     total_tokens += 1\n",
    "    print(len(sentences))\n",
    "perplexity = torch.exp(total_loss / total_tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piyush/anaconda3/envs/srinath/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"stanfordnlp/backpack-gpt2\"\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=stanfordnlp/backpack-gpt2,config=config,trust_remote_code=True \\\n",
    "    --tasks lambada_openai \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sense vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change it according to paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"stanfordnlp/backpack-gpt2\"\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, config=config, trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\",pad_token = '<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer([\"The\",\"Ceo\",\"said\",\"that\"], max_length=20, truncation=True, padding='max_length', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257],\n",
       "        [   34,    68,    78, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257],\n",
       "        [30079, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257],\n",
       "        [ 5562, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]]), 'attention_mask': tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(x)\n",
    "senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 20, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 50257).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 1])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(x)\n",
    "all_senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 16, 1, 768])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_senses = all_senses.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 16, 768])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4196, 50257, 50257, 50257, 50257]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\" Apple\",max_length=5,padding='max_length', return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tokenizer(\" Apple\",max_length=1,padding='max_length', return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(tmp)\n",
    "senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 768])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = senses.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sense_10 = all_senses[:,9,:]\n",
    "tasty_sense_10 = senses[9, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sense_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasty_sense_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sense_3 = all_senses[:,2,:]\n",
    "tasty_sense_3 = senses[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = torch.matmul(vocab_sense_3, tasty_sense_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-18.0290,   3.2239,  23.9513,  ...,  90.3603,  22.1850,   2.1527],\n",
       "       grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = torch.argsort(dot_product, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4196, 16108, 17180,  ...,  3569, 21549, 21191])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sorted_indices[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tokenizer(\" Apple\",max_length=1,padding='max_length', return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(tmp)\n",
    "senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = senses.squeeze()\n",
    "tasty_sense_10 = senses[12, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = model.lm_head(tasty_sense_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50264])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = torch.argsort(dot_product, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' iPad'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sorted_indices[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iOS'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses = senses.squeeze()\n",
    "tasty_sense_7 = senses[7, :]\n",
    "dot_product = model.lm_head(tasty_sense_7)\n",
    "sorted_indices = torch.argsort(dot_product, descending=True)\n",
    "tokenizer.decode(sorted_indices[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [10848], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\" arts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer(tokenizer.bos_token+\" The building in paris is\",return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 768])"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = model.lm_head(senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 50264])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dot_product[:,:,:,10848]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.normalize(weights, p=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7])"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 1])"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextl_hidden_states = model.backpack.gpt2_model(x).last_hidden_state # (bs, s, d)\n",
    "contextualization = model.backpack.sense_weight_net(contextl_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualization.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_context = contextualization * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.run_with_custom_contextualization(x,new_context).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 50264])"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(y,dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' watchdog countryside codes shaping UID Building career'"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.argmax(y,dim=-1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer(tokenizer.bos_token+\" My husband said that\",return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(x)\n",
    "senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextl_hidden_states = model.backpack.gpt2_model(x).last_hidden_state # (bs, s, d)\n",
    "contextualization = model.backpack.sense_weight_net(contextl_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= torch.ones_like(contextualization)\n",
    "weights[:,10,:,:]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualization=contextualization*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.run_with_custom_contextualization(x,contextualization).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first and he he'"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.argmax(y,dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simmilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"stanfordnlp/backpack-gpt2\"\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, config=config, trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\",pad_token = '<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5661], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer(\"this\",return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.backpack.word_embeddings(x)\n",
    "senses = model.backpack.sense_network(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = [' take',' walk']\n",
    "word2 = [' remove',' trail']  # add space\n",
    "h_score = [6.81,4.81]\n",
    "m_score =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simm(w1,w2):\n",
    "    x1 = tokenizer(w1,return_tensors='pt')['input_ids']\n",
    "    x1 = model.backpack.word_embeddings(x1)\n",
    "    x1 = model.backpack.sense_network(x1).detach()\n",
    "    x1 = x1[:,:,0,:]\n",
    "    x1 = x1.squeeze()\n",
    "    x1 = F.normalize(x1,p=2,dim=1)\n",
    "    x2 = tokenizer(w2,return_tensors='pt')['input_ids']\n",
    "    x2 = model.backpack.word_embeddings(x2)\n",
    "    x2 = model.backpack.sense_network(x2).detach()\n",
    "    x2 = x2[:,:,0,:]\n",
    "    x2 = x2.squeeze()\n",
    "    x2 = F.normalize(x2,p=2,dim=1)\n",
    "    sim_list = torch.sum(torch.multiply(x1,x2),dim=1)\n",
    "    #print(sim_list)\n",
    "    return(sim_list.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0006)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simm('take','walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word1)):\n",
    "    m_score.append(simm(word1[i],word2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0634), tensor(0.0486)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearman_corr, _ = spearmanr(h_score, m_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMVERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = []\n",
    "word2 = []  # add space\n",
    "h_score = []\n",
    "m_score =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/piyush/srinath/NLP/Project/NLP/Hamvir/SimVerb-3500.txt', 'r') as file:\n",
    "    # Iterate through each line\n",
    "    for line in file:\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split('\\t')\n",
    "\n",
    "        # Extract word1, word2, and the score\n",
    "        word1.append(\" \"+ columns[0])\n",
    "        word2.append(\" \"+ columns[1])\n",
    "        h_score.append(float(columns[3]))  # Assuming the score is a floating-point number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word1)):\n",
    "    m_score.append(simm(word1[i],word2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' remove'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearman_corr, _ = spearmanr(h_score, m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4468468531403537"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMMLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = []\n",
    "word2 = []  # add space\n",
    "h_score = []\n",
    "m_score =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/piyush/srinath/NLP/Project/NLP/Hamvir/SimLex-999.txt', 'r') as file:\n",
    "    # Iterate through each line\n",
    "    header = next(file)\n",
    "    for line in file:\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split('\\t')\n",
    "\n",
    "        # Extract word1, word2, and the score\n",
    "        word1.append(\" \"+ columns[0])\n",
    "        word2.append(\" \"+ columns[1])\n",
    "        h_score.append(float(columns[3]))  # Assuming the score is a floating-point number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word1)):\n",
    "    m_score.append(simm(word1[i],word2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr, _ = spearmanr(h_score, m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396491328014148"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Model, GPT2Config\n",
    "# configuration = GPT2Config()\n",
    "# model = GPT2Model(configuration)\n",
    "from transformers import GPT2LMHeadModel\n",
    "# from transformers import GPT2Config\n",
    "# config= GPT2Config()\n",
    "# from transformers.models.gpt2.modeling_gpt2 import GPT2Model, GPT2PreTrainedModel\n",
    "# model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\",pad_token = '<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = tokenizer.encode(w1,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simm(w1,w2):\n",
    "    x1 = tokenizer(w1,return_tensors='pt')['input_ids']\n",
    "    x1 = model.transformer.wte(x1).detach() # (1, 1, 768)\n",
    "    x1 = x1[:,-1,:]  # (1,768)\n",
    "    x1 = F.normalize(x1,p=2,dim=1)\n",
    "    x2 = tokenizer(w2,return_tensors='pt')['input_ids']\n",
    "    x2 = model.transformer.wte(x2).detach() # (1, 1, 768)\n",
    "    x2 = x2[:,-1,:] # (1,768)\n",
    "    x2 = F.normalize(x2,p=2,dim=1)\n",
    "    sim_list = torch.sum(torch.multiply(x1,x2))\n",
    "    #print(sim_list)\n",
    "    return(sim_list.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = []\n",
    "word2 = []  # add space\n",
    "h_score = []\n",
    "m_score =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/piyush/srinath/NLP/Project/NLP/Hamvir/SimLex-999.txt', 'r') as file:\n",
    "    # Iterate through each line\n",
    "    header = next(file)\n",
    "    for line in file:\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split('\\t')\n",
    "\n",
    "        # Extract word1, word2, and the score\n",
    "        word1.append(\" \"+ columns[0])\n",
    "        word2.append(\" \"+ columns[1])\n",
    "        h_score.append(float(columns[3]))  # Assuming the score is a floating-point number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word1)):\n",
    "    m_score.append(simm(word1[i],word2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr, _ = spearmanr(h_score, m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46565706841842996"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = []\n",
    "word2 = []  # add space\n",
    "h_score = []\n",
    "m_score =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/piyush/srinath/NLP/Project/NLP/Hamvir/SimVerb-3500.txt', 'r') as file:\n",
    "    # Iterate through each line\n",
    "    for line in file:\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split('\\t')\n",
    "\n",
    "        # Extract word1, word2, and the score\n",
    "        word1.append(\" \"+ columns[0])\n",
    "        word2.append(\" \"+ columns[1])\n",
    "        h_score.append(float(columns[3]))  # Assuming the score is a floating-point number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(word1)):\n",
    "    m_score.append(simm(word1[i],word2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr, _ = spearmanr(h_score, m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2911671264006562"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srinath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
